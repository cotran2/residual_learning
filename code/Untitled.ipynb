{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (MyDenseLayer)         multiple                  157000    \n",
      "_________________________________________________________________\n",
      "output (MyDenseLayer)        multiple                  2010      \n",
      "=================================================================\n",
      "Total params: 159,010\n",
      "Trainable params: 159,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch : 1 ----- Loss : 0.3806563913822174 ----- Acc : 0.9498000144958496\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (MyDenseLayer)         multiple                  157000    \n",
      "_________________________________________________________________\n",
      "2 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "output (MyDenseLayer)        multiple                  2010      \n",
      "=================================================================\n",
      "Total params: 199,210\n",
      "Trainable params: 42,210\n",
      "Non-trainable params: 157,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch : 2 ----- Loss : 0.8120077848434448 ----- Acc : 0.9138000011444092\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (MyDenseLayer)         multiple                  157000    \n",
      "_________________________________________________________________\n",
      "2 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "3 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "output (MyDenseLayer)        multiple                  2010      \n",
      "=================================================================\n",
      "Total params: 239,410\n",
      "Trainable params: 42,210\n",
      "Non-trainable params: 197,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch : 3 ----- Loss : 0.3072812259197235 ----- Acc : 0.9161999821662903\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (MyDenseLayer)         multiple                  157000    \n",
      "_________________________________________________________________\n",
      "2 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "3 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "4 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "output (MyDenseLayer)        multiple                  2010      \n",
      "=================================================================\n",
      "Total params: 279,610\n",
      "Trainable params: 42,210\n",
      "Non-trainable params: 237,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch : 4 ----- Loss : 0.3036216199398041 ----- Acc : 0.9161999821662903\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (MyDenseLayer)         multiple                  157000    \n",
      "_________________________________________________________________\n",
      "2 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "3 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "4 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "5 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "output (MyDenseLayer)        multiple                  2010      \n",
      "=================================================================\n",
      "Total params: 319,810\n",
      "Trainable params: 42,210\n",
      "Non-trainable params: 277,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch : 5 ----- Loss : 0.3028627932071686 ----- Acc : 0.9107999801635742\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (MyDenseLayer)         multiple                  157000    \n",
      "_________________________________________________________________\n",
      "2 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "3 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "4 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "5 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "6 (MyDenseLayer)             multiple                  40200     \n",
      "_________________________________________________________________\n",
      "output (MyDenseLayer)        multiple                  2010      \n",
      "=================================================================\n",
      "Total params: 360,010\n",
      "Trainable params: 42,210\n",
      "Non-trainable params: 317,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch : 6 ----- Loss : 0.298721581697464 ----- Acc : 0.9147999882698059\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-107bcc911ede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_sm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mepoch_loss_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cotran/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cotran/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/workspace/cotran/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cotran/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1583\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1586\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cotran/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6110\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6111\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6112\u001b[0;31m         transpose_a, \"transpose_b\", transpose_b)\n\u001b[0m\u001b[1;32m   6113\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6114\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import regularizers\n",
    "import pandas as pd\n",
    "from tensorflow.python.ops import nn\n",
    "import numpy as np\n",
    "from models import MyModel,MyDenseLayer, cal_acc\n",
    "if tf.__version__ != \"2.0.0\":\n",
    "    tf.enable_eager_execution()\n",
    "def my_loss(y_pred,y_true):\n",
    "    y_true = tf.one_hot(y_true, n_outputs, dtype=tf.float32)\n",
    "    return  tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true,y_pred))\n",
    "\"\"\"\n",
    "    Hyper-parameters\n",
    "\"\"\"\n",
    "n_inputs = 28*28\n",
    "n_outputs = 10\n",
    "n_hiddens = 200\n",
    "n_epochs = 100\n",
    "n_batches = 1000\n",
    "epoch = 0\n",
    "target_loss = 1e-5\n",
    "thresh_hold = 1e-4\n",
    "\"\"\"\n",
    "    Load data\n",
    "\"\"\"\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape((len(x_train),28*28))\n",
    "x_test = x_test.reshape((len(x_test),28*28))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(len(x_train)).batch(n_batches)\n",
    "\"\"\"\n",
    "    Train data\n",
    "\"\"\"\n",
    "m_model = MyModel()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "epoch = 0\n",
    "while (epoch < n_epochs) or (epoch_loss_avg.result() < target_loss):\n",
    "    epoch += 1\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    accuracy = 0\n",
    "    for x, y in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            out_sm = m_model(x)\n",
    "            batch_loss = my_loss(out_sm, y)\n",
    "            variables = m_model.trainable_variables\n",
    "            grads = tape.gradient(batch_loss, variables)\n",
    "            optimizer.apply_gradients(zip(grads, variables))\n",
    "        epoch_loss_avg(batch_loss)\n",
    "    if epoch%1 == 0:\n",
    "        print(m_model.summary())\n",
    "    test_out = m_model(x_test)\n",
    "    accuracy = cal_acc(test_out, y_test)\n",
    "    m_model.sparsify_weights()\n",
    "    m_model.add_layer()\n",
    "    print('Epoch : {} ----- Loss : {} ----- Acc : {}'.format(epoch, epoch_loss_avg.result(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8284, shape=(10,), dtype=float32, numpy=\n",
       "array([0.10048118, 0.10995017, 0.09862196, 0.10275455, 0.09594902,\n",
       "       0.08713035, 0.09923879, 0.10736267, 0.09792877, 0.10058253],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sm = m_model(x)\n",
    "batch_loss = my_loss(out_sm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8320, shape=(), dtype=float32, numpy=2.300185>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = m_model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'my_model/input/kernel_input:0' shape=(784, 200) dtype=float32, numpy=\n",
       " array([[-0.        , -0.        ,  0.06086512, ..., -0.        ,\n",
       "          0.02553575,  0.00459374],\n",
       "        [ 0.00098739,  0.05507488, -0.        , ...,  0.03410412,\n",
       "          0.03262541,  0.04916674],\n",
       "        [-0.        , -0.        , -0.        , ...,  0.05693038,\n",
       "          0.02237913, -0.        ],\n",
       "        ...,\n",
       "        [ 0.00118908,  0.02149661,  0.03032578, ...,  0.02388858,\n",
       "          0.05714952,  0.02639412],\n",
       "        [ 0.04205748, -0.        , -0.        , ...,  0.02172448,\n",
       "          0.00297545, -0.        ],\n",
       "        [-0.        , -0.        , -0.        , ..., -0.        ,\n",
       "          0.01751576,  0.03941942]], dtype=float32)>,\n",
       " <tf.Variable 'my_model/input/bias_input:0' shape=(200,) dtype=float32, numpy=\n",
       " array([ 0.08839815, -0.        ,  0.04403333,  0.11430001,  0.02603001,\n",
       "         0.06121723, -0.        ,  0.04109554,  0.04321741, -0.        ,\n",
       "         0.09764183, -0.        ,  0.00895448, -0.        , -0.        ,\n",
       "        -0.        ,  0.04601985, -0.        , -0.        , -0.        ,\n",
       "        -0.        ,  0.10217281, -0.        ,  0.0780577 , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        ,  0.04258992,\n",
       "         0.09810399, -0.        ,  0.04428943,  0.03716375, -0.        ,\n",
       "        -0.        , -0.        ,  0.00377568,  0.0440106 , -0.        ,\n",
       "        -0.        , -0.        , -0.        ,  0.1456256 ,  0.06337053,\n",
       "         0.06106002,  0.01321557, -0.        ,  0.01856483, -0.        ,\n",
       "         0.10380361, -0.        , -0.        ,  0.04831792, -0.        ,\n",
       "         0.10224523, -0.        ,  0.20988916, -0.        , -0.        ,\n",
       "        -0.        ,  0.0359115 , -0.        , -0.        , -0.        ,\n",
       "         0.05479352,  0.05646026, -0.        ,  0.04608035,  0.1215274 ,\n",
       "         0.04820721, -0.        ,  0.01638915, -0.        , -0.        ,\n",
       "         0.11279356, -0.        , -0.        ,  0.11411513, -0.        ,\n",
       "         0.0934131 ,  0.04530793,  0.04256479,  0.07814717,  0.05604974,\n",
       "         0.00596227, -0.        ,  0.0369192 ,  0.0087912 ,  0.03123306,\n",
       "        -0.        ,  0.122382  , -0.        , -0.        ,  0.03267849,\n",
       "        -0.        , -0.        ,  0.01894183,  0.08105936,  0.01111628,\n",
       "         0.05383381,  0.01917764, -0.        ,  0.10928845, -0.        ,\n",
       "        -0.        , -0.        ,  0.1363761 ,  0.10822339, -0.        ,\n",
       "         0.06999913,  0.0637622 ,  0.06955528, -0.        , -0.        ,\n",
       "        -0.        ,  0.08000863, -0.        , -0.        ,  0.09662307,\n",
       "         0.10285437,  0.04735725,  0.05439552,  0.00305017,  0.01882451,\n",
       "         0.05694043,  0.03177804, -0.        ,  0.06954467,  0.10400134,\n",
       "        -0.        ,  0.0810395 ,  0.0287122 ,  0.09000535,  0.04080527,\n",
       "         0.08122624, -0.        , -0.        , -0.        ,  0.03796552,\n",
       "         0.04429297, -0.        , -0.        ,  0.00879166, -0.        ,\n",
       "         0.04461712, -0.        ,  0.0071961 , -0.        ,  0.07419153,\n",
       "        -0.        , -0.        , -0.        ,  0.11855263,  0.05877738,\n",
       "         0.11633368,  0.04266044,  0.10385443, -0.        ,  0.01925267,\n",
       "         0.1004447 , -0.        ,  0.03577645,  0.00488012,  0.02168049,\n",
       "         0.04668711,  0.03963526,  0.18648419, -0.        , -0.        ,\n",
       "         0.01242011, -0.        , -0.        ,  0.06595881, -0.        ,\n",
       "         0.00253958, -0.        ,  0.13693257,  0.10993817, -0.        ,\n",
       "         0.15346465,  0.00425404,  0.11070561,  0.09121273, -0.        ,\n",
       "         0.03358571,  0.01985756,  0.00658152,  0.12181178,  0.07106188,\n",
       "         0.04233402,  0.12771085,  0.01637517,  0.07497535, -0.        ,\n",
       "        -0.        ,  0.17580125,  0.03386797,  0.09612415, -0.        ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'my_model/2/kernel_2:0' shape=(200, 200) dtype=float32, numpy=\n",
       " array([[-0.        , -0.        , -0.        , ...,  0.01155367,\n",
       "         -0.        , -0.        ],\n",
       "        [-0.        , -0.        , -0.        , ..., -0.        ,\n",
       "         -0.        , -0.        ],\n",
       "        [-0.        , -0.        , -0.        , ..., -0.        ,\n",
       "         -0.        , -0.        ],\n",
       "        ...,\n",
       "        [-0.        , -0.        , -0.        , ..., -0.        ,\n",
       "          0.00508025, -0.        ],\n",
       "        [-0.        , -0.        , -0.        , ..., -0.        ,\n",
       "         -0.        , -0.        ],\n",
       "        [-0.        ,  0.01760233, -0.        , ..., -0.        ,\n",
       "         -0.        , -0.        ]], dtype=float32)>,\n",
       " <tf.Variable 'my_model/2/bias_2:0' shape=(200,) dtype=float32, numpy=\n",
       " array([ 0.00836437, -0.        , -0.        ,  0.09490528,  0.01946264,\n",
       "        -0.        ,  0.00139241, -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "         0.0423555 , -0.        , -0.        , -0.        , -0.        ,\n",
       "         0.05118395, -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        ,  0.00561956,\n",
       "         0.0103878 , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        ,  0.02520197,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        ,  0.0093737 , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "         0.01786899,  0.03870231, -0.        , -0.        , -0.        ,\n",
       "        -0.        ,  0.08664671, -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        ,  0.02159609, -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        ,  0.01193958, -0.        , -0.        , -0.        ,\n",
       "        -0.        ,  0.06824432, -0.        , -0.        , -0.        ,\n",
       "         0.07145803, -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        ,  0.00123023, -0.        , -0.        ,\n",
       "        -0.        , -0.        ,  0.09799477, -0.        , -0.        ,\n",
       "        -0.        , -0.        ,  0.05456015, -0.        ,  0.03513983,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        ,  0.03712492,\n",
       "         0.01015523, -0.        , -0.        ,  0.04633521, -0.        ,\n",
       "         0.07603122, -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "         0.05019725, -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        ,  0.07524314, -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "         0.10155266, -0.        , -0.        ,  0.03662465, -0.        ,\n",
       "         0.05089091, -0.        , -0.        , -0.        , -0.        ,\n",
       "         0.02926604,  0.0641372 , -0.        , -0.        , -0.        ,\n",
       "        -0.        , -0.        , -0.        , -0.        , -0.        ],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'my_model/3/kernel_3:0' shape=(200, 200) dtype=float32, numpy=\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       " <tf.Variable 'my_model/3/bias_3:0' shape=(200,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'my_model/output/kernel_output:0' shape=(200, 10) dtype=float32, numpy=\n",
       " array([[-0.01425088,  0.13563165, -0.01498509, ...,  0.08793909,\n",
       "         -0.04558857,  0.01397344],\n",
       "        [ 0.10707623, -0.05021864, -0.01367084, ..., -0.0614942 ,\n",
       "         -0.08500376,  0.00625282],\n",
       "        [ 0.1488377 , -0.11112904, -0.07270599, ...,  0.22627482,\n",
       "         -0.10299712, -0.03193383],\n",
       "        ...,\n",
       "        [ 0.06905282,  0.03989077,  0.02358567, ..., -0.15227823,\n",
       "         -0.04505146,  0.07742253],\n",
       "        [ 0.02514238, -0.04404501, -0.15769963, ...,  0.16892283,\n",
       "         -0.07981264,  0.03211567],\n",
       "        [-0.05407444,  0.16087855, -0.02598952, ..., -0.05629349,\n",
       "          0.0165901 , -0.10630109]], dtype=float32)>,\n",
       " <tf.Variable 'my_model/output/bias_output:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.12891749,  0.21015242, -0.11524215, -0.07154594,  0.03949671,\n",
       "         0.14995706,  0.0129751 ,  0.15978065, -0.13386472,  0.04219377],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=34126, shape=(784, 200), dtype=float32, numpy=\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       " <tf.Tensor: id=34125, shape=(200,), dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Tensor: id=34116, shape=(200, 10), dtype=float32, numpy=\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>,\n",
       " <tf.Tensor: id=34114, shape=(10,), dtype=float32, numpy=\n",
       " array([-1.2472081e-02,  6.9167456e-03, -2.6228433e-03,  1.6113985e-02,\n",
       "         3.2455167e-03, -1.2112548e-02,  7.0276183e-05,  1.7475951e-04,\n",
       "         4.9599321e-03, -4.2737788e-03], dtype=float32)>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y in train_dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "        out_sm = m_model(x)\n",
    "        batch_loss = my_loss(out_sm, y)\n",
    "        variables = m_model.trainable_variables\n",
    "        grads = tape.gradient(batch_loss, variables)\n",
    "        optimizer.apply_gradients(zip(grads, variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
